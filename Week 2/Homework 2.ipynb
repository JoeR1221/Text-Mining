{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "#Equivalent to CountVectorizer but with tf-idf norm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "## For Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['WW_Neg_1.txt', 'WW_Neg_2.txt', 'WW_Neg_3.txt', 'WW_Neg_4.txt', 'WW_Pos_1.txt', 'WW_Pos_2.txt', 'WW_Pos_3.txt', 'WW_Pos_4.txt']\n"
     ]
    }
   ],
   "source": [
    "#Locate Corpus Folder\n",
    "path=\"C:/Users/Joe/WWReviews\"\n",
    "FileNameList=os.listdir(path)\n",
    "print(type(FileNameList))\n",
    "print(FileNameList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListOfCompleteFilePaths=[]    #empty list that will hold (eventually) all complete\n",
    "ListOfJustFileNames=[]  # names so I can use them to CREATE LABELS for my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Joe/WWReviews/WW_Neg_1.txt\n",
      "WW_Neg_1\n",
      "C:/Users/Joe/WWReviews/WW_Neg_2.txt\n",
      "WW_Neg_2\n",
      "C:/Users/Joe/WWReviews/WW_Neg_3.txt\n",
      "WW_Neg_3\n",
      "C:/Users/Joe/WWReviews/WW_Neg_4.txt\n",
      "WW_Neg_4\n",
      "C:/Users/Joe/WWReviews/WW_Pos_1.txt\n",
      "WW_Pos_1\n",
      "C:/Users/Joe/WWReviews/WW_Pos_2.txt\n",
      "WW_Pos_2\n",
      "C:/Users/Joe/WWReviews/WW_Pos_3.txt\n",
      "WW_Pos_3\n",
      "C:/Users/Joe/WWReviews/WW_Pos_4.txt\n",
      "WW_Pos_4\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## Here, we loop through all files in the\n",
    "## path. For each file, we BUILD a complete\n",
    "## path and place that complete path into\n",
    "## The list we created above. At the same\n",
    "## time we will also store the file names\n",
    "## (just the names) so we can use them\n",
    "## later as labels....\n",
    "######################################################\n",
    "\n",
    "for name in os.listdir(path):\n",
    "\n",
    "    print(path+ \"/\" + name)  ## concatenate your path to \\\\ to the file name.\n",
    "    ## Print the above to SEE what it does. \n",
    "    nextfile=path+ \"/\" + name   ## save the complete path the you just built\n",
    "    ListOfCompleteFilePaths.append(nextfile)  ## place it in the list.\n",
    "\n",
    "    \n",
    "    #### Here - we are taking name and splitting it with .\n",
    "    #### This will give us JUST the file name and not the .txt part\n",
    "    nextnameL=name.split(\".\")   ##If name is Dog1.txt is splits it into Dog1   and txt\n",
    "    print(nextnameL[0])  ### SEE what this is. Why I am using [0]? Make sure you know!\n",
    "    ListOfJustFileNames.append(nextnameL[0]) ## add the name to the list of names\n",
    "\n",
    "###########################-------------------end of for loop ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of complete file paths...\n",
      "\n",
      "['C:/Users/Joe/WWReviews/WW_Neg_1.txt', 'C:/Users/Joe/WWReviews/WW_Neg_2.txt', 'C:/Users/Joe/WWReviews/WW_Neg_3.txt', 'C:/Users/Joe/WWReviews/WW_Neg_4.txt', 'C:/Users/Joe/WWReviews/WW_Pos_1.txt', 'C:/Users/Joe/WWReviews/WW_Pos_2.txt', 'C:/Users/Joe/WWReviews/WW_Pos_3.txt', 'C:/Users/Joe/WWReviews/WW_Pos_4.txt']\n",
      "list of just names:\n",
      "\n",
      "['WW_Neg_1', 'WW_Neg_2', 'WW_Neg_3', 'WW_Neg_4', 'WW_Pos_1', 'WW_Pos_2', 'WW_Pos_3', 'WW_Pos_4']\n"
     ]
    }
   ],
   "source": [
    "## Let's SEE what we created................\n",
    "print(\"List of complete file paths...\\n\")\n",
    "print(ListOfCompleteFilePaths)\n",
    "print(\"list of just names:\\n\")\n",
    "print(ListOfJustFileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "###\n",
    "###             Use CountVectorizer to convert text\n",
    "###             to a document-term matrix and then a Dataframe\n",
    "###\n",
    "#####################################################################\n",
    "\n",
    "## Step 1: Instantiate YOUR own CountVectorizer\n",
    "\n",
    "MyVect3=CountVectorizer(input='filename', ##notice input=\"filename\n",
    "                        stop_words='english',\n",
    "                        #max_features=1000  ## this is an option\n",
    "                        )\n",
    "\n",
    "## NOw I can vectorize using my list of complete paths to my files\n",
    "## Using MyVect3 I can use the fit_transform method. This method\n",
    "## takes as a parameter the list of complete file paths that we created above.\n",
    "## This is why we needed to create the list of file paths.\n",
    "\n",
    "X_WW=MyVect3.fit_transform(ListOfCompleteFilePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 109)\t1\n",
      "  (0, 92)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 81)\t2\n",
      "  (0, 27)\t1\n",
      "  (0, 98)\t1\n",
      "  (0, 79)\t1\n",
      "  (0, 25)\t1\n",
      "  (0, 59)\t1\n",
      "  (0, 86)\t1\n",
      "  (0, 85)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 95)\t1\n",
      "  (0, 75)\t1\n",
      "  (0, 46)\t1\n",
      "  (0, 107)\t1\n",
      "  (0, 101)\t1\n",
      "  (0, 72)\t1\n",
      "  (1, 99)\t1\n",
      "  (1, 29)\t1\n",
      "  (1, 22)\t1\n",
      "  (1, 39)\t1\n",
      "  (1, 76)\t1\n",
      "  (1, 71)\t1\n",
      "  :\t:\n",
      "  (6, 18)\t1\n",
      "  (6, 49)\t1\n",
      "  (6, 100)\t1\n",
      "  (6, 102)\t1\n",
      "  (6, 65)\t1\n",
      "  (7, 104)\t1\n",
      "  (7, 103)\t1\n",
      "  (7, 90)\t1\n",
      "  (7, 4)\t1\n",
      "  (7, 67)\t1\n",
      "  (7, 93)\t1\n",
      "  (7, 24)\t1\n",
      "  (7, 23)\t1\n",
      "  (7, 8)\t1\n",
      "  (7, 35)\t1\n",
      "  (7, 106)\t1\n",
      "  (7, 89)\t1\n",
      "  (7, 7)\t1\n",
      "  (7, 55)\t1\n",
      "  (7, 63)\t1\n",
      "  (7, 64)\t1\n",
      "  (7, 82)\t1\n",
      "  (7, 74)\t1\n",
      "  (7, 2)\t1\n",
      "  (7, 11)\t1\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## NOw - what do we have?\n",
    "## Let's SEE\n",
    "## Note that X_DH is a variable name. \n",
    "## What I have created here is a DocumentTermMatrix\n",
    "#################################\n",
    "\n",
    "print(X_WW)   ## NOt pretty to look at! Let's REFORMAT IT to a Dataframe...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1984', '80s', '84', 'action', 'actors', 'advantage', 'alongside', 'appeal', 'appealing', 'avengers', 'beating', 'beckons', 'bigger', 'boasting', 'brighter', 'celebrated', 'charming', 'cinema', 'coloured', 'comfortably', 'committee', 'contained', 'course', 'create', 'crew', 'delivering', 'deserves', 'double', 'dynamic', 'emerge', 'emotional', 'endgame', 'energy', 'entertaining', 'exciting', 'fanciful', 'far', 'feels', 'felt', 'film', 'gift', 'heart', 'hope', 'imagination', 'inconsequential', 'increasingly', 'installment', 'irritating', 'lacks', 'leg', 'like', 'lot', 'loved', 'lower', 'man', 'mere', 'mess', 'message', 'middle', 'mindless', 'moments', 'movie', 'neon', 'nods', 'non', 'notch', 'original', 'perform', 'performances', 'pieces', 'plot', 'poorly', 'possible', 'powerful', 'presentations', 'previous', 'prove', 'ramped', 'rote', 'scheme', 'sequel', 'set', 'sexist', 'sitting', 'spider', 'steers', 'story', 'strong', 'superhero', 'superheroes', 'supporting', 'taken', 'takes', 'technical', 'tier', 'tone', 'uplifting', 'verse', 'villain', 'villains', 'warmer', 'way', 'wearing', 'woman', 'wonder', 'wonderful', 'world', 'worst', 'written', 'ww84']\n"
     ]
    }
   ],
   "source": [
    "## Hmm - that's not quite what we want...\n",
    "## Let's get the feature names which ARE the words\n",
    "## The method  get_feature_names  will return all the WORDS in all the docs\n",
    "## These are called the \"features\" because they are the names of the columns. \n",
    "\n",
    "ColumnNames3=MyVect3.get_feature_names()\n",
    "print(ColumnNames3)  ## have a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1984  80s  84  action  actors  advantage  alongside  appeal  appealing  \\\n",
      "0     0    1   0       0       0          1          0       0          0   \n",
      "1     0    0   0       0       0          0          0       0          0   \n",
      "2     0    0   0       0       0          0          0       0          0   \n",
      "3     0    0   0       1       0          0          0       0          0   \n",
      "4     0    0   0       0       0          0          0       0          0   \n",
      "5     0    0   0       0       0          0          0       0          0   \n",
      "6     1    0   0       1       0          0          1       0          0   \n",
      "7     0    0   1       0       1          0          0       1          1   \n",
      "\n",
      "   avengers  ...  warmer  way  wearing  woman  wonder  wonderful  world  \\\n",
      "0         0  ...       0    1        0      0       0          0      0   \n",
      "1         0  ...       0    0        0      0       0          0      0   \n",
      "2         1  ...       0    0        0      1       1          0      0   \n",
      "3         0  ...       0    0        0      0       0          0      0   \n",
      "4         0  ...       0    0        0      0       0          0      0   \n",
      "5         0  ...       0    0        0      0       0          1      0   \n",
      "6         0  ...       1    0        1      1       1          0      0   \n",
      "7         0  ...       0    0        0      1       1          0      1   \n",
      "\n",
      "   worst  written  ww84  \n",
      "0      1        0     1  \n",
      "1      0        1     0  \n",
      "2      0        0     0  \n",
      "3      0        0     0  \n",
      "4      0        0     1  \n",
      "5      0        0     0  \n",
      "6      0        0     0  \n",
      "7      0        0     0  \n",
      "\n",
      "[8 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "## OK good - NOW convert to a DataFrame. \n",
    "## !!! NOTICE that I first had to convert my X_DH to an array. If you skip\n",
    "## this, the code will not work. \n",
    "\n",
    "CorpusDF_WW=pd.DataFrame(X_WW.toarray(),columns=ColumnNames3)\n",
    "print(CorpusDF_WW)   ## Here is our dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "##\n",
    "##              Now we need to add the labels to \n",
    "##              our dataframe. This will take a few\n",
    "##              steps....\n",
    "############################################################\n",
    "\n",
    "## First, let's create an empty dictionary. \n",
    "## A dictionary is a very useful structure in python. \n",
    "\n",
    "MyDict={}\n",
    "\n",
    "## Next, let's use a loop from 0 to how ever many files\n",
    "## we have. Notice that we use len here and not a number.\n",
    "## This means that we can have any number of files in our\n",
    "## Corpus and this will still work. That is important!\n",
    "## Also, unlike R, Python starts at 0 and not 1 for most things.\n",
    "\n",
    "for i in range(0, len(ListOfJustFileNames)):\n",
    "    MyDict[i] = ListOfJustFileNames[i]  ## build the dictionary\n",
    "    ## The above will associate MyDict[0] with the first name\n",
    "    ## and MyDict[1] with the second name, and so on....\n",
    "##------------------------end of for loop---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MY DICT: {0: 'WW_Neg_1', 1: 'WW_Neg_2', 2: 'WW_Neg_3', 3: 'WW_Neg_4', 4: 'WW_Pos_1', 5: 'WW_Pos_2', 6: 'WW_Pos_3', 7: 'WW_Pos_4'}\n"
     ]
    }
   ],
   "source": [
    "## Let's SEE what we created....\n",
    "print(\"MY DICT:\", MyDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WW_Pos_\n"
     ]
    }
   ],
   "source": [
    "### This is NOT good enough!\n",
    "### We need the labels to be categories. \n",
    "## Let's fix this...\n",
    "\n",
    "## Let's test the idea first\n",
    "temp = MyDict[7].rstrip('0123456789')\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now - let's FIX the entire dictionary\n",
    "for i in range(0, len(ListOfJustFileNames)):\n",
    "    MyDict[i] = MyDict[i].rstrip('0123456789')\n",
    "    ## The [0] will give us just the name and not the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MY DICT: {0: 'WW_Neg_', 1: 'WW_Neg_', 2: 'WW_Neg_', 3: 'WW_Neg_', 4: 'WW_Pos_', 5: 'WW_Pos_', 6: 'WW_Pos_', 7: 'WW_Pos_'}\n",
      "         1984  80s  84  action  actors  advantage  alongside  appeal  \\\n",
      "WW_Neg_     0    1   0       0       0          1          0       0   \n",
      "WW_Neg_     0    0   0       0       0          0          0       0   \n",
      "WW_Neg_     0    0   0       0       0          0          0       0   \n",
      "WW_Neg_     0    0   0       1       0          0          0       0   \n",
      "WW_Pos_     0    0   0       0       0          0          0       0   \n",
      "WW_Pos_     0    0   0       0       0          0          0       0   \n",
      "WW_Pos_     1    0   0       1       0          0          1       0   \n",
      "WW_Pos_     0    0   1       0       1          0          0       1   \n",
      "\n",
      "         appealing  avengers  ...  warmer  way  wearing  woman  wonder  \\\n",
      "WW_Neg_          0         0  ...       0    1        0      0       0   \n",
      "WW_Neg_          0         0  ...       0    0        0      0       0   \n",
      "WW_Neg_          0         1  ...       0    0        0      1       1   \n",
      "WW_Neg_          0         0  ...       0    0        0      0       0   \n",
      "WW_Pos_          0         0  ...       0    0        0      0       0   \n",
      "WW_Pos_          0         0  ...       0    0        0      0       0   \n",
      "WW_Pos_          0         0  ...       1    0        1      1       1   \n",
      "WW_Pos_          1         0  ...       0    0        0      1       1   \n",
      "\n",
      "         wonderful  world  worst  written  ww84  \n",
      "WW_Neg_          0      0      1        0     1  \n",
      "WW_Neg_          0      0      0        1     0  \n",
      "WW_Neg_          0      0      0        0     0  \n",
      "WW_Neg_          0      0      0        0     0  \n",
      "WW_Pos_          0      0      0        0     1  \n",
      "WW_Pos_          1      0      0        0     0  \n",
      "WW_Pos_          0      0      0        0     0  \n",
      "WW_Pos_          0      1      0        0     0  \n",
      "\n",
      "[8 rows x 110 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "### CHECK IT!\n",
    "print(\"MY DICT:\", MyDict)  \n",
    "## OK - now we can place this into our dataframe....    \n",
    "\n",
    "CorpusDF_WW=CorpusDF_WW.rename(MyDict, axis=\"index\")\n",
    "print(CorpusDF_WW)\n",
    "\n",
    "## That's pretty!\n",
    "## WHat can you do from here? Anything!\n",
    "## First - see what data object type you actually have\n",
    "\n",
    "print(type(CorpusDF_WW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 1 0 0 0 1 0 2 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1\n",
      "  0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  1 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0\n",
      "  0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0\n",
      "  0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0\n",
      "  0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      "  0 0]\n",
      " [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0\n",
      "  0 0]\n",
      " [0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      "  0 0]]\n"
     ]
    }
   ],
   "source": [
    "## We have what we expected - a data frame.\n",
    "# Convert DataFrame to matrix\n",
    "\n",
    "MyMatrixWW = CorpusDF_WW.values\n",
    "\n",
    "## Check it\n",
    "\n",
    "print(type(MyMatrixWW))\n",
    "print(MyMatrixWW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "###\n",
    "###             Use TfidfVectorizer to convert text\n",
    "###             to a document-term matrix and then a Dataframe\n",
    "###             and normalize using tf-idf\n",
    "###\n",
    "#####################################################################\n",
    "\n",
    "MyVect_TF=TfidfVectorizer(input='filename',\n",
    "                        stop_words='english',\n",
    "                        max_features=100\n",
    "                        )\n",
    "\n",
    "## NOw I can vectorize using my list of complete paths to my files\n",
    "TF_WW=MyVect_TF.fit_transform(ListOfCompleteFilePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's get the feature names which ARE the words\n",
    "ColumnNamesTF=MyVect_TF.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1984       80s        84    action    actors  advantage  alongside  \\\n",
      "0  0.000000  0.220799  0.000000  0.000000  0.000000   0.220799   0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "3  0.000000  0.000000  0.000000  0.287303  0.000000   0.000000   0.000000   \n",
      "4  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "5  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "6  0.251158  0.000000  0.000000  0.210490  0.000000   0.000000   0.251158   \n",
      "7  0.000000  0.000000  0.235402  0.000000  0.235402   0.000000   0.000000   \n",
      "\n",
      "     appeal  appealing  avengers  ...    warmer       way   wearing     woman  \\\n",
      "0  0.000000   0.000000  0.000000  ...  0.000000  0.220799  0.000000  0.000000   \n",
      "1  0.000000   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.000000   0.000000  0.253549  ...  0.000000  0.000000  0.000000  0.183365   \n",
      "3  0.000000   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "4  0.000000   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "5  0.000000   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "6  0.000000   0.000000  0.000000  ...  0.251158  0.000000  0.251158  0.181635   \n",
      "7  0.235402   0.235402  0.000000  ...  0.000000  0.000000  0.000000  0.170241   \n",
      "\n",
      "     wonder  wonderful     world     worst   written      ww84  \n",
      "0  0.000000   0.000000  0.000000  0.220799  0.000000  0.185047  \n",
      "1  0.000000   0.000000  0.000000  0.000000  0.344935  0.000000  \n",
      "2  0.183365   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "4  0.000000   0.000000  0.000000  0.000000  0.000000  0.220020  \n",
      "5  0.000000   0.338985  0.000000  0.000000  0.000000  0.000000  \n",
      "6  0.181635   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "7  0.170241   0.000000  0.235402  0.000000  0.000000  0.000000  \n",
      "\n",
      "[8 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "## OK good - but we want a document topic model A DTM (matrix of counts)\n",
    "CorpusDF_WW_TF=pd.DataFrame(TF_WW.toarray(),columns=ColumnNamesTF)\n",
    "print(CorpusDF_WW_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1984</th>\n",
       "      <th>80s</th>\n",
       "      <th>84</th>\n",
       "      <th>action</th>\n",
       "      <th>actors</th>\n",
       "      <th>advantage</th>\n",
       "      <th>alongside</th>\n",
       "      <th>appeal</th>\n",
       "      <th>appealing</th>\n",
       "      <th>avengers</th>\n",
       "      <th>...</th>\n",
       "      <th>warmer</th>\n",
       "      <th>way</th>\n",
       "      <th>wearing</th>\n",
       "      <th>woman</th>\n",
       "      <th>wonder</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>world</th>\n",
       "      <th>worst</th>\n",
       "      <th>written</th>\n",
       "      <th>ww84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344935</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183365</td>\n",
       "      <td>0.183365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.251158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251158</td>\n",
       "      <td>0.181635</td>\n",
       "      <td>0.181635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235402</td>\n",
       "      <td>0.235402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170241</td>\n",
       "      <td>0.170241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1984       80s        84    action    actors  advantage  alongside  \\\n",
       "0  0.000000  0.220799  0.000000  0.000000  0.000000   0.220799   0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.287303  0.000000   0.000000   0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "6  0.251158  0.000000  0.000000  0.210490  0.000000   0.000000   0.251158   \n",
       "7  0.000000  0.000000  0.235402  0.000000  0.235402   0.000000   0.000000   \n",
       "\n",
       "     appeal  appealing  avengers  ...    warmer       way   wearing     woman  \\\n",
       "0  0.000000   0.000000  0.000000  ...  0.000000  0.220799  0.000000  0.000000   \n",
       "1  0.000000   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000   0.000000  0.253549  ...  0.000000  0.000000  0.000000  0.183365   \n",
       "3  0.000000   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.000000   0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.000000   0.000000  0.000000  ...  0.251158  0.000000  0.251158  0.181635   \n",
       "7  0.235402   0.235402  0.000000  ...  0.000000  0.000000  0.000000  0.170241   \n",
       "\n",
       "     wonder  wonderful     world     worst   written      ww84  \n",
       "0  0.000000   0.000000  0.000000  0.220799  0.000000  0.185047  \n",
       "1  0.000000   0.000000  0.000000  0.000000  0.344935  0.000000  \n",
       "2  0.183365   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000   0.000000  0.000000  0.000000  0.000000  0.220020  \n",
       "5  0.000000   0.338985  0.000000  0.000000  0.000000  0.000000  \n",
       "6  0.181635   0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "7  0.170241   0.000000  0.235402  0.000000  0.000000  0.000000  \n",
       "\n",
       "[8 rows x 100 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorpusDF_WW_TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "## That's pretty!\n",
    "## WHat can you do from here? Anything!\n",
    "## First - see what data object type you actually have\n",
    "\n",
    "print(type(CorpusDF_WW_TF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[0.         0.22079912 0.         0.         0.         0.22079912\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.22079912 0.         0.22079912 0.         0.         0.\n",
      "  0.         0.         0.         0.22079912 0.         0.\n",
      "  0.         0.         0.         0.         0.22079912 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.22079912 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.22079912 0.         0.\n",
      "  0.22079912 0.         0.         0.         0.22079912 0.\n",
      "  0.37009378 0.         0.         0.         0.22079912 0.22079912\n",
      "  0.         0.         0.         0.         0.         0.22079912\n",
      "  0.         0.22079912 0.         0.         0.22079912 0.\n",
      "  0.         0.22079912 0.         0.         0.         0.\n",
      "  0.         0.22079912 0.         0.18504689]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.34493527 0.         0.\n",
      "  0.         0.         0.         0.34493527 0.         0.\n",
      "  0.         0.         0.         0.         0.28908268 0.28908268\n",
      "  0.         0.         0.         0.         0.         0.34493527\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.34493527 0.         0.         0.\n",
      "  0.         0.34493527 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.34493527\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.34493527 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25354919 0.25354919 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.25354919\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.21249401 0.25354919 0.25354919 0.         0.\n",
      "  0.         0.21249401 0.         0.         0.25354919 0.\n",
      "  0.         0.         0.         0.         0.1607706  0.\n",
      "  0.         0.         0.         0.25354919 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.50709839 0.         0.\n",
      "  0.         0.21249401 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.25354919 0.         0.\n",
      "  0.         0.         0.         0.1833649  0.1833649  0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.28730325 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.34281205 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.34281205 0.         0.         0.         0.28730325 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.28730325 0.34281205 0.         0.         0.\n",
      "  0.34281205 0.         0.         0.         0.21737044 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.34281205 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.34281205 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.26252975\n",
      "  0.26252975 0.26252975 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.26252975 0.\n",
      "  0.         0.26252975 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26252975 0.         0.         0.166465   0.\n",
      "  0.         0.         0.         0.         0.         0.26252975\n",
      "  0.26252975 0.         0.         0.         0.26252975 0.\n",
      "  0.         0.         0.         0.         0.         0.26252975\n",
      "  0.22002042 0.         0.         0.         0.         0.\n",
      "  0.26252975 0.22002042 0.         0.         0.         0.\n",
      "  0.         0.         0.26252975 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.22002042]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33898549 0.33898549 0.33898549 0.\n",
      "  0.         0.         0.33898549 0.         0.         0.\n",
      "  0.         0.33898549 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.2840963\n",
      "  0.33898549 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.33898549 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.33898549\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.25115782 0.         0.         0.21048985 0.         0.\n",
      "  0.25115782 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.25115782\n",
      "  0.25115782 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.21048985 0.         0.         0.         0.\n",
      "  0.25115782 0.         0.         0.25115782 0.         0.\n",
      "  0.         0.         0.         0.         0.15925428 0.25115782\n",
      "  0.         0.         0.25115782 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.25115782 0.         0.         0.\n",
      "  0.         0.         0.25115782 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.25115782 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.25115782 0.         0.25115782 0.18163547 0.18163547 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.23540156 0.         0.23540156 0.\n",
      "  0.         0.23540156 0.23540156 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23540156 0.23540156\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.23540156 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.23540156\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23540156 0.23540156 0.         0.         0.23540156 0.\n",
      "  0.         0.         0.         0.         0.         0.23540156\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.23540156 0.         0.         0.         0.\n",
      "  0.         0.         0.23540156 0.23540156 0.         0.\n",
      "  0.23540156 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.17024067 0.17024067 0.\n",
      "  0.23540156 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to matrix\n",
    "\n",
    "MyMatrixWW = CorpusDF_WW_TF.values\n",
    "\n",
    "## Check it\n",
    "\n",
    "print(type(MyMatrixWW))\n",
    "print(MyMatrixWW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
